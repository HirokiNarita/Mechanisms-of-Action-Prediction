{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nsys.path.append('../input/moa-mlp-maxout/modules')","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lib"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport random\nimport math\nimport time\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.metrics import log_loss\n\nimport category_encoders as ce\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nimport common as com\nfrom MLP_Dataset import TrainDataset, TestDataset\nfrom MLP_Model import FCBlock, TabularNN\nfrom trainer import train_fn, validate_fn, inference_fn, AverageMeter\nfrom config import CFG","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# util"},{"metadata":{"trusted":true},"cell_type":"code","source":"out_base_path = \"./\"\nmodel_path = \"../input/moa-mlp-maxout/max_out_model/model\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = com.get_logger(out_base_path)\ncom.seed_everything(seed=42)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input'\n#os.listdir('../input/lish-moa')\nos.listdir(base_dir)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"['lish-moa', 'iterative-stratification', 'moa-mlp-maxout']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_features.merge(train_targets_scored, on='sig_id')\ntarget_cols = [c for c in train_targets_scored.columns if c not in ['sig_id']]\ncols = target_cols + ['cp_type']\ntrain[cols].groupby('cp_type').sum().sum(1)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"cp_type\nctl_vehicle        0\ntrt_cp         16844\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features.shape, test_features.shape)\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\ntest = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nprint(train.shape, test.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(23814, 876) (3982, 876)\n(21948, 1082) (3624, 876)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# split"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = train.copy()\nFold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[target_cols])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(21948, 1083)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['cp_time', 'cp_dose']\nnum_features = [c for c in train.columns if train.dtypes[c] != 'object']\nnum_features = [c for c in num_features if c not in cat_features]\nnum_features = [c for c in num_features if c not in target_cols]\ntarget = train[target_cols].values\n\ndef cate2num(df):\n    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 3, 'D2': 4})\n    return df\n\ntrain = cate2num(train)\ntest = cate2num(test)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_single_nn(cfg, train, test, folds, num_features, cat_features, target, target_cols, device, model_path, fold_num=0, seed=42):\n    oof = None\n    log_df = None\n    # Set seed\n    logger.info(f'Set seed {seed}')\n    com.seed_everything(seed=seed)\n    \n    # loader\n    #trn_idx = folds[folds['fold'] != fold_num].index\n    #val_idx = folds[folds['fold'] == fold_num].index\n    #train_folds = train.loc[trn_idx].reset_index(drop=True)\n    #valid_folds = train.loc[val_idx].reset_index(drop=True)\n    #train_target = target[trn_idx]\n    #valid_target = target[val_idx]\n    #train_dataset = TrainDataset(train_folds, num_features, cat_features, train_target)\n    #valid_dataset = TrainDataset(valid_folds, num_features, cat_features, valid_target)\n    #train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, \n    #                          num_workers=4, pin_memory=True, drop_last=True)\n    #valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n    #                          num_workers=4, pin_memory=True, drop_last=False)\n\n    # model\n    model = TabularNN(cfg, num_features, target_cols)\n    model.to(device)\n    #optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n    #scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n    #                                          max_lr=1e-2, epochs=cfg.epochs, steps_per_epoch=len(train_loader))\n\n    # log\n    #log_df = pd.DataFrame(columns=(['EPOCH']+['TRAIN_LOSS']+['VALID_LOSS']) )\n\n    # train & validate\n    #best_loss = np.inf\n    #early_stopping_cnt = 0\n    #for epoch in range(cfg.epochs):\n    #    train_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, device)\n    #    valid_loss, val_preds = validate_fn(valid_loader, model, device)\n    #    log_row = {'EPOCH': epoch, \n    #               'TRAIN_LOSS': train_loss,\n    #               'VALID_LOSS': valid_loss,\n    #              }\n    #    log_df = log_df.append(pd.DataFrame(log_row, index=[0]), sort=False)\n    #    #logger.info(log_df.tail(1))\n    #    if valid_loss < best_loss:\n    #        logger.info(f'epoch{epoch} save best model... tr_loss:{train_loss}, val_loss{valid_loss}')\n    #        best_loss = valid_loss\n    #        oof = np.zeros((len(train), len(target_cols)))\n    #        oof[val_idx] = val_preds\n    #        torch.save(model.state_dict(), model_path + f\"/fold{fold_num}_seed{seed}.pth\")\n    #        best_epoch = epoch\n    #        early_stopping_cnt = 0\n    #    else:\n    #        early_stopping_cnt += 1\n    #        if early_stopping_cnt == cfg.early_stopping_rounds:\n    #            logger.info(f'best epoch: epoch{best_epoch}')\n    #            break\n\n    # predictions\n    test_dataset = TestDataset(test, num_features, cat_features)\n    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, \n                             num_workers=4, pin_memory=True)\n    model = TabularNN(cfg, num_features, target_cols)\n    model.load_state_dict(torch.load(model_path + f\"/fold{fold_num}_seed{seed}.pth\"))\n    model.to(device)\n    predictions = inference_fn(test_loader, model, device)\n    \n    # del\n    torch.cuda.empty_cache()\n\n    return oof, predictions, log_df\n\n\ndef run_kfold_nn(cfg, train, test, folds, num_features, cat_features, target, target_cols, device, model_path, n_fold=5, seed=42):\n\n    #oof = np.zeros((len(train), len(target_cols)))\n    predictions = np.zeros((len(test), len(target_cols)))\n    log_dfs = []\n    for _fold in range(n_fold):\n        logger.info(\"Fold {}\".format(_fold))\n        _oof, _predictions, log_df = run_single_nn(cfg,\n                                                   train,\n                                                   test,\n                                                   folds,\n                                                   num_features, \n                                                   cat_features,\n                                                   target,\n                                                   target_cols,\n                                                   device,\n                                                   model_path,\n                                                   fold_num=_fold,\n                                                   seed=seed)\n        #oof += _oof\n        predictions += _predictions / n_fold\n        #log_dfs.append(log_df)\n\n    score = 0\n    for i in range(target.shape[1]):\n        _score = log_loss(target[:,i], oof[:,i])\n        score += _score / target.shape[1]\n    #logger.info(f\"CV score: {score}\")\n    \n    return oof, predictions, log_dfs","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n\n#SEED = [0, 1, 2]\n#for seed in SEED:\noof, predictions, log_dfs = run_kfold_nn(CFG,\n                                         train, test, folds, \n                                         num_features, cat_features, target, target_cols,\n                                         device,\n                                         model_path=model_path,\n                                         n_fold=5, seed=42)\n#score = 0\n#for i in range(target.shape[1]):\n#    _score = log_loss(target[:,i], oof[:,i])\n#    score += _score / target.shape[1]\n#logger.info(f\"Seed Averaged CV score: {score}\")","execution_count":14,"outputs":[{"output_type":"stream","text":"Fold 0\nSet seed 42\nFold 1\nSet seed 42\nFold 2\nSet seed 42\nFold 3\nSet seed 42\nFold 4\nSet seed 42\nCV score: 0.12867376499702737\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[target_cols] = predictions\ntest[['sig_id']+target_cols].to_csv(out_base_path + '/pred.csv', index=False)","execution_count":15,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Final result with 'cp_type'=='ctl_vehicle' data\n#result = train_targets_scored.drop(columns=target_cols)\\\n#            .merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n#y_true = train_targets_scored[target_cols].values\n#y_pred = result[target_cols].values\n#score = 0\n#for i in range(y_true.shape[1]):\n#    _score = log_loss(y_true[:,i], y_pred[:,i])\n#    score += _score / y_true.shape[1]\n#logger.info(f\"Final result: {score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# sub"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n0  id_0004d9e33                     0.001106                0.002928   \n1  id_001897cda                     0.000409                0.000880   \n2  id_002429b5b                     0.000000                0.000000   \n3  id_00276f245                     0.000812                0.000951   \n4  id_0027f1083                     0.001964                0.004205   \n\n   acat_inhibitor  acetylcholine_receptor_agonist  \\\n0        0.002517                        0.020588   \n1        0.001383                        0.001295   \n2        0.000000                        0.000000   \n3        0.002484                        0.009740   \n4        0.003759                        0.022235   \n\n   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n0                           0.030557                        0.003090   \n1                           0.002897                        0.003593   \n2                           0.000000                        0.000000   \n3                           0.006423                        0.008106   \n4                           0.038166                        0.004897   \n\n   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n0                    0.001616                       0.008007   \n1                    0.002744                       0.015397   \n2                    0.000000                       0.000000   \n3                    0.003800                       0.002179   \n4                    0.012973                       0.003220   \n\n   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                    0.000451  ...                               0.003321   \n1                    0.003070  ...                               0.000584   \n2                    0.000000  ...                               0.000000   \n3                    0.000648  ...                               0.000667   \n4                    0.000665  ...                               0.001348   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0      0.001241         0.005976           0.000701   \n1      0.000940         0.002385           0.000442   \n2      0.000000         0.000000           0.000000   \n3      0.000830         0.013751           0.040342   \n4      0.001004         0.014565           0.001652   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                   0.000890                               0.000914   \n1                   0.009371                               0.000428   \n2                   0.000000                               0.000000   \n3                   0.013643                               0.000697   \n4                   0.001100                               0.001265   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0         0.000936   0.003557                    0.004832       0.002749  \n1         0.005754   0.000531                    0.000833       0.002043  \n2         0.000000   0.000000                    0.000000       0.000000  \n3         0.002475   0.002737                    0.000760       0.005610  \n4         0.002200   0.002624                    0.000682       0.002128  \n\n[5 rows x 207 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>...</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_0004d9e33</td>\n      <td>0.001106</td>\n      <td>0.002928</td>\n      <td>0.002517</td>\n      <td>0.020588</td>\n      <td>0.030557</td>\n      <td>0.003090</td>\n      <td>0.001616</td>\n      <td>0.008007</td>\n      <td>0.000451</td>\n      <td>...</td>\n      <td>0.003321</td>\n      <td>0.001241</td>\n      <td>0.005976</td>\n      <td>0.000701</td>\n      <td>0.000890</td>\n      <td>0.000914</td>\n      <td>0.000936</td>\n      <td>0.003557</td>\n      <td>0.004832</td>\n      <td>0.002749</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_001897cda</td>\n      <td>0.000409</td>\n      <td>0.000880</td>\n      <td>0.001383</td>\n      <td>0.001295</td>\n      <td>0.002897</td>\n      <td>0.003593</td>\n      <td>0.002744</td>\n      <td>0.015397</td>\n      <td>0.003070</td>\n      <td>...</td>\n      <td>0.000584</td>\n      <td>0.000940</td>\n      <td>0.002385</td>\n      <td>0.000442</td>\n      <td>0.009371</td>\n      <td>0.000428</td>\n      <td>0.005754</td>\n      <td>0.000531</td>\n      <td>0.000833</td>\n      <td>0.002043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_002429b5b</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_00276f245</td>\n      <td>0.000812</td>\n      <td>0.000951</td>\n      <td>0.002484</td>\n      <td>0.009740</td>\n      <td>0.006423</td>\n      <td>0.008106</td>\n      <td>0.003800</td>\n      <td>0.002179</td>\n      <td>0.000648</td>\n      <td>...</td>\n      <td>0.000667</td>\n      <td>0.000830</td>\n      <td>0.013751</td>\n      <td>0.040342</td>\n      <td>0.013643</td>\n      <td>0.000697</td>\n      <td>0.002475</td>\n      <td>0.002737</td>\n      <td>0.000760</td>\n      <td>0.005610</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_0027f1083</td>\n      <td>0.001964</td>\n      <td>0.004205</td>\n      <td>0.003759</td>\n      <td>0.022235</td>\n      <td>0.038166</td>\n      <td>0.004897</td>\n      <td>0.012973</td>\n      <td>0.003220</td>\n      <td>0.000665</td>\n      <td>...</td>\n      <td>0.001348</td>\n      <td>0.001004</td>\n      <td>0.014565</td>\n      <td>0.001652</td>\n      <td>0.001100</td>\n      <td>0.001265</td>\n      <td>0.002200</td>\n      <td>0.002624</td>\n      <td>0.000682</td>\n      <td>0.002128</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 207 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}