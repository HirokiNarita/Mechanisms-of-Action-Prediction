{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import category_encoders as ce\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import common as com\n",
    "import pth_modeling\n",
    "import pth_preprocessing\n",
    "import pth_model\n",
    "from config import IO_CFG\n",
    "from config import MODEL_CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# set seed = 42\n",
    "############################################################################\n",
    "com.seed_everything(42)\n",
    "############################################################################\n",
    "# load config and set logger\n",
    "############################################################################\n",
    "#with open(\"./config.yaml\", 'rb') as f:\n",
    "#    config = yaml.load(f)\n",
    "\n",
    "log_folder = IO_CFG.input_root + '/{0}.log'.format(datetime.date.today())\n",
    "logger = com.setup_logger(log_folder, '00_baseline_MLP.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/hiroki/working/kaggle/Mechanisms-of-Action-Prediction/result/MLP/baseline/config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "# Setting I/O path\n",
    "############################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = IO_CFG.input_root\n",
    "# output dirs\n",
    "OUTPUT_ROOT = IO_CFG.output_root\n",
    "MODEL_DIR = IO_CFG.output_root + '/models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# copy config\n",
    "shutil.copy('./config.yaml', OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(INPUT_ROOT+'/train_features.csv')\n",
    "train_targets_scored = pd.read_csv(INPUT_ROOT+'/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(INPUT_ROOT+'/train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv(INPUT_ROOT+'/test_features.csv')\n",
    "submission = pd.read_csv(INPUT_ROOT+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp_type\n",
       "ctl_vehicle        0\n",
       "trt_cp         16844\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref: https://www.kaggle.com/c/lish-moa/discussion/180165\n",
    "# check if labels for 'ctl_vehicle' are all 0.\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "target_cols = [c for c in train_targets_scored.columns if c not in ['sig_id']]\n",
    "cols = target_cols + ['cp_type']\n",
    "train[cols].groupby('cp_type').sum().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876) (3982, 876)\n",
      "(21948, 1082) (3624, 876)\n"
     ]
    }
   ],
   "source": [
    "# constrcut train&test except 'cp_type'=='ctl_vehicle' data\n",
    "print(train_features.shape, test_features.shape)\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1083)\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[target_cols])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cp_time', 'cp_dose']\n",
    "num_features = [c for c in train.columns if train.dtypes[c] != 'object']\n",
    "num_features = [c for c in num_features if c not in cat_features]\n",
    "num_features = [c for c in num_features if c not in target_cols]\n",
    "target = train[target_cols].values\n",
    "\n",
    "def cate2num(df):\n",
    "    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 3, 'D2': 4})\n",
    "    return df\n",
    "\n",
    "train = cate2num(train)\n",
    "test = cate2num(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_nn(cfg, train, test, folds, num_features, cat_features, target, device, fold_num=0, seed=42):\n",
    "    \n",
    "    # Set seed\n",
    "    logger.info(f'Set seed {seed}')\n",
    "    com.seed_everything(seed=seed)\n",
    "\n",
    "    # loader\n",
    "    trn_idx = folds[folds['fold'] != fold_num].index\n",
    "    val_idx = folds[folds['fold'] == fold_num].index\n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    train_target = target[trn_idx]\n",
    "    valid_target = target[val_idx]\n",
    "    train_dataset = pth_preprocessing.TrainDataset(train_folds, num_features, cat_features, train_target)\n",
    "    valid_dataset = pth_preprocessing.TrainDataset(valid_folds, num_features, cat_features, valid_target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, \n",
    "                              num_workers=4, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                              num_workers=4, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # model\n",
    "    model = pth_model.TabularNN(cfg)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=cfg.epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    # log\n",
    "    log_df = pd.DataFrame(columns=(['EPOCH']+['TRAIN_LOSS']+['VALID_LOSS']) )\n",
    "\n",
    "    # train & validate\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(cfg.epochs):\n",
    "        train_loss = pth_modeling.train_fn(train_loader, model, optimizer, epoch, scheduler, device)\n",
    "        valid_loss, val_preds = pth_modeling.validate_fn(valid_loader, model, device)\n",
    "        log_row = {'EPOCH': epoch, \n",
    "                   'TRAIN_LOSS': train_loss,\n",
    "                   'VALID_LOSS': valid_loss,\n",
    "                  }\n",
    "        log_df = log_df.append(pd.DataFrame(log_row, index=[0]), sort=False)\n",
    "        #logger.info(log_df.tail(1))\n",
    "        if valid_loss < best_loss:\n",
    "            logger.info(f'epoch{epoch} save best model... {valid_loss}')\n",
    "            best_loss = valid_loss\n",
    "            oof = np.zeros((len(train), cfg.target_cols))\n",
    "            oof[val_idx] = val_preds\n",
    "            torch.save(model.state_dict(), '{}/models'.format(IO_CFG.output_root)+f\"/fold{fold_num}_seed{seed}.pth\")\n",
    "\n",
    "    # predictions\n",
    "    test_dataset = pth_preprocessing.TestDataset(test, num_features, cat_features)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                             num_workers=4, pin_memory=True)\n",
    "    model = pth_model.TabularNN(cfg)\n",
    "    model.load_state_dict(torch.load('{}/models'.format(IO_CFG.output_root)+f\"/fold{fold_num}_seed{seed}.pth\"))\n",
    "    model.to(device)\n",
    "    predictions = pth_modeling.inference_fn(test_loader, model, device)\n",
    "    \n",
    "    # del\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_nn(cfg, train, test, folds, num_features, cat_features, target, device, n_fold=5, seed=42):\n",
    "\n",
    "    oof = np.zeros((len(train), cfg.target_cols))\n",
    "    predictions = np.zeros((len(test), cfg.target_cols))\n",
    "\n",
    "    for _fold in range(n_fold):\n",
    "        logger.info(\"Fold {}\".format(_fold))\n",
    "        _oof, _predictions = run_single_nn(cfg,\n",
    "                                           train,\n",
    "                                           test,\n",
    "                                           folds,\n",
    "                                           num_features, \n",
    "                                           cat_features,\n",
    "                                           target, \n",
    "                                           device,\n",
    "                                           fold_num=_fold,\n",
    "                                           seed=seed)\n",
    "        oof += _oof\n",
    "        predictions += _predictions / n_fold\n",
    "\n",
    "    score = 0\n",
    "    for i in range(target.shape[1]):\n",
    "        _score = log_loss(target[:,i], oof[:,i])\n",
    "        score += _score / target.shape[1]\n",
    "    logger.info(f\"CV score: {score}\")\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-19 17:01:07,073 - 00_baseline_MLP.ipynb - INFO - Fold 0\n",
      "2020-10-19 17:01:07,074 - 00_baseline_MLP.ipynb - INFO - Set seed 0\n",
      "2020-10-19 17:01:11,105 - 00_baseline_MLP.ipynb - INFO - epoch0 save best model... 0.020932637995155635\n",
      "2020-10-19 17:01:13,710 - 00_baseline_MLP.ipynb - INFO - epoch1 save best model... 0.018820307481024152\n",
      "2020-10-19 17:01:16,545 - 00_baseline_MLP.ipynb - INFO - epoch2 save best model... 0.018154521185081613\n",
      "2020-10-19 17:01:19,472 - 00_baseline_MLP.ipynb - INFO - epoch3 save best model... 0.017682247374690475\n",
      "2020-10-19 17:01:24,682 - 00_baseline_MLP.ipynb - INFO - epoch5 save best model... 0.017219796780165886\n",
      "2020-10-19 17:01:38,917 - 00_baseline_MLP.ipynb - INFO - epoch10 save best model... 0.017118015102532975\n",
      "2020-10-19 17:01:41,856 - 00_baseline_MLP.ipynb - INFO - epoch11 save best model... 0.01694158597261664\n",
      "2020-10-19 17:01:47,426 - 00_baseline_MLP.ipynb - INFO - epoch13 save best model... 0.01666934386124847\n",
      "2020-10-19 17:01:50,179 - 00_baseline_MLP.ipynb - INFO - epoch14 save best model... 0.016664944916267736\n",
      "2020-10-19 17:01:53,112 - 00_baseline_MLP.ipynb - INFO - epoch15 save best model... 0.016439915026680213\n",
      "2020-10-19 17:01:55,933 - 00_baseline_MLP.ipynb - INFO - epoch16 save best model... 0.016345628836788324\n",
      "2020-10-19 17:01:58,578 - 00_baseline_MLP.ipynb - INFO - epoch17 save best model... 0.016341631905364556\n",
      "2020-10-19 17:02:01,277 - 00_baseline_MLP.ipynb - INFO - epoch18 save best model... 0.01630931063884008\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inference_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4834e9f7426c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                       \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                       n_fold=5, seed=seed)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moof\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_oof\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_predictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0f9d7ce2ee9e>\u001b[0m in \u001b[0;36mrun_kfold_nn\u001b[0;34m(cfg, train, test, folds, num_features, cat_features, target, device, n_fold, seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                            \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                            \u001b[0mfold_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                            seed=seed)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moof\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_oof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_predictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-da72d1ef600f>\u001b[0m in \u001b[0;36mrun_single_nn\u001b[0;34m(cfg, train, test, folds, num_features, cat_features, target, device, fold_num, seed)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/models'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO_CFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"/fold{fold_num}_seed{seed}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# del\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# Seed Averaging for solid result\n",
    "oof = np.zeros((len(train), MODEL_CFG.target_cols))\n",
    "predictions = np.zeros((len(test), MODEL_CFG.target_cols))\n",
    "\n",
    "SEED = [0, 1, 2]\n",
    "for seed in SEED:\n",
    "    _oof, _predictions = run_kfold_nn(MODEL_CFG, \n",
    "                                      train, test, folds, \n",
    "                                      num_features, cat_features, target,\n",
    "                                      device,\n",
    "                                      n_fold=5, seed=seed)\n",
    "    oof += _oof / len(SEED)\n",
    "    predictions += _predictions / len(SEED)\n",
    "\n",
    "score = 0\n",
    "for i in range(target.shape[1]):\n",
    "    _score = log_loss(target[:,i], oof[:,i])\n",
    "    score += _score / target.shape[1]\n",
    "logger.info(f\"Seed Averaged CV score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = oof\n",
    "train[['sig_id']+target_cols].to_csv('oof.csv', index=False)\n",
    "\n",
    "test[target_cols] = predictions\n",
    "test[['sig_id']+target_cols].to_csv('pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result with 'cp_type'=='ctl_vehicle' data\n",
    "result = train_targets_scored.drop(columns=target_cols)\\\n",
    "            .merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = result[target_cols].values\n",
    "score = 0\n",
    "for i in range(y_true.shape[1]):\n",
    "    _score = log_loss(y_true[:,i], y_pred[:,i])\n",
    "    score += _score / y_true.shape[1]\n",
    "logger.info(f\"Final result: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
