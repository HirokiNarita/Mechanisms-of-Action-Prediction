{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "sys.path.append('../input/modules')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import common as com\n",
    "from MLP_Dataset import TrainDataset, TestDataset\n",
    "from MLP_Model import FCBlock, TabularNN\n",
    "from trainer import train_fn, validate_fn, inference_fn, AverageMeter\n",
    "from config import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_base_path = \"./\"\n",
    "model_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = com.get_logger(out_base_path)\n",
    "com.seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/kaggle/input'\n",
    "#os.listdir('../input/lish-moa')\n",
    "os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "target_cols = [c for c in train_targets_scored.columns if c not in ['sig_id']]\n",
    "cols = target_cols + ['cp_type']\n",
    "train[cols].groupby('cp_type').sum().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape, test_features.shape)\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = train.copy()\n",
    "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[target_cols])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cp_time', 'cp_dose']\n",
    "num_features = [c for c in train.columns if train.dtypes[c] != 'object']\n",
    "num_features = [c for c in num_features if c not in cat_features]\n",
    "num_features = [c for c in num_features if c not in target_cols]\n",
    "target = train[target_cols].values\n",
    "\n",
    "def cate2num(df):\n",
    "    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 3, 'D2': 4})\n",
    "    return df\n",
    "\n",
    "train = cate2num(train)\n",
    "test = cate2num(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_nn(cfg, train, test, folds, num_features, cat_features, target, target_cols, device, model_path, fold_num=0, seed=42):\n",
    "    oof = None\n",
    "    log_df = None\n",
    "    # Set seed\n",
    "    logger.info(f'Set seed {seed}')\n",
    "    com.seed_everything(seed=seed)\n",
    "    \n",
    "    # loader\n",
    "    #trn_idx = folds[folds['fold'] != fold_num].index\n",
    "    #val_idx = folds[folds['fold'] == fold_num].index\n",
    "    #train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    #valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    #train_target = target[trn_idx]\n",
    "    #valid_target = target[val_idx]\n",
    "    #train_dataset = TrainDataset(train_folds, num_features, cat_features, train_target)\n",
    "    #valid_dataset = TrainDataset(valid_folds, num_features, cat_features, valid_target)\n",
    "    #train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, \n",
    "    #                          num_workers=4, pin_memory=True, drop_last=True)\n",
    "    #valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "    #                          num_workers=4, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # model\n",
    "    model = TabularNN(cfg, num_features, target_cols)\n",
    "    model.to(device)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    #scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "    #                                          max_lr=1e-2, epochs=cfg.epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    # log\n",
    "    #log_df = pd.DataFrame(columns=(['EPOCH']+['TRAIN_LOSS']+['VALID_LOSS']) )\n",
    "\n",
    "    # train & validate\n",
    "    #best_loss = np.inf\n",
    "    #early_stopping_cnt = 0\n",
    "    #for epoch in range(cfg.epochs):\n",
    "    #    train_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, device)\n",
    "    #    valid_loss, val_preds = validate_fn(valid_loader, model, device)\n",
    "    #    log_row = {'EPOCH': epoch, \n",
    "    #               'TRAIN_LOSS': train_loss,\n",
    "    #               'VALID_LOSS': valid_loss,\n",
    "    #              }\n",
    "    #    log_df = log_df.append(pd.DataFrame(log_row, index=[0]), sort=False)\n",
    "    #    #logger.info(log_df.tail(1))\n",
    "    #    if valid_loss < best_loss:\n",
    "    #        logger.info(f'epoch{epoch} save best model... tr_loss:{train_loss}, val_loss{valid_loss}')\n",
    "    #        best_loss = valid_loss\n",
    "    #        oof = np.zeros((len(train), len(target_cols)))\n",
    "    #        oof[val_idx] = val_preds\n",
    "    #        torch.save(model.state_dict(), model_path + f\"/fold{fold_num}_seed{seed}.pth\")\n",
    "    #        best_epoch = epoch\n",
    "    #        early_stopping_cnt = 0\n",
    "    #    else:\n",
    "    #        early_stopping_cnt += 1\n",
    "    #        if early_stopping_cnt == cfg.early_stopping_rounds:\n",
    "    #            logger.info(f'best epoch: epoch{best_epoch}')\n",
    "    #            break\n",
    "\n",
    "    # predictions\n",
    "    test_dataset = TestDataset(test, num_features, cat_features)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                             num_workers=4, pin_memory=True)\n",
    "    model = TabularNN(cfg, num_features, target_cols)\n",
    "    model.load_state_dict(torch.load(model_path + f\"/fold{fold_num}_seed{seed}.pth\"))\n",
    "    model.to(device)\n",
    "    predictions = inference_fn(test_loader, model, device)\n",
    "    \n",
    "    # del\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return oof, predictions, log_df\n",
    "\n",
    "\n",
    "def run_kfold_nn(cfg, train, test, folds, num_features, cat_features, target, target_cols, device, model_path, n_fold=5, seed=42):\n",
    "\n",
    "    #oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    log_dfs = []\n",
    "    for _fold in range(n_fold):\n",
    "        logger.info(\"Fold {}\".format(_fold))\n",
    "        _oof, _predictions, log_df = run_single_nn(cfg,\n",
    "                                                   train,\n",
    "                                                   test,\n",
    "                                                   folds,\n",
    "                                                   num_features, \n",
    "                                                   cat_features,\n",
    "                                                   target,\n",
    "                                                   target_cols,\n",
    "                                                   device,\n",
    "                                                   model_path,\n",
    "                                                   fold_num=_fold,\n",
    "                                                   seed=seed)\n",
    "        oof += _oof\n",
    "        predictions += _predictions / n_fold\n",
    "        log_dfs.append(log_df)\n",
    "\n",
    "    score = 0\n",
    "    for i in range(target.shape[1]):\n",
    "        _score = log_loss(target[:,i], oof[:,i])\n",
    "        score += _score / target.shape[1]\n",
    "    logger.info(f\"CV score: {score}\")\n",
    "    \n",
    "    return oof, predictions, log_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "#SEED = [0, 1, 2]\n",
    "#for seed in SEED:\n",
    "oof, predictions, log_dfs = run_kfold_nn(CFG,\n",
    "                                         train, test, folds, \n",
    "                                         num_features, cat_features, target, target_cols,\n",
    "                                         device,\n",
    "                                         model_path=model_path,\n",
    "                                         n_fold=5, seed=42)\n",
    "#score = 0\n",
    "#for i in range(target.shape[1]):\n",
    "#    _score = log_loss(target[:,i], oof[:,i])\n",
    "#    score += _score / target.shape[1]\n",
    "#logger.info(f\"Seed Averaged CV score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = predictions\n",
    "test[['sig_id']+target_cols].to_csv(out_base_path + '/pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result with 'cp_type'=='ctl_vehicle' data\n",
    "#result = train_targets_scored.drop(columns=target_cols)\\\n",
    "#            .merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "#y_true = train_targets_scored[target_cols].values\n",
    "#y_pred = result[target_cols].values\n",
    "#score = 0\n",
    "#for i in range(y_true.shape[1]):\n",
    "#    _score = log_loss(y_true[:,i], y_pred[:,i])\n",
    "#    score += _score / y_true.shape[1]\n",
    "#logger.info(f\"Final result: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
